from pathlib import Path
import argparse

import pandas as pd

import gm_classifier as gm


def main(input_dir: Path, model_base_dir: Path, output_ffp: Path):
    csv_files = input_dir.glob("*.csv")

    if any(["comp_X.csv" in str(cur_file) for cur_file in csv_files]):
        print("Loading the feature csv files")
        feature_df = gm.utils.load_features_from_dir(input_dir)
    else:
        print("Extracting the features from the V1A files")
        raise NotImplementedError

    print("Loading the model")
    model = gm.RecordCompModel(model_base_dir)
    model.load()

    print("Running the predictions")
    y_hat, y_hat_std = model.predict(feature_df, n_preds=100)
    est_df = pd.DataFrame(index=feature_df.index.values, data=y_hat, columns=model.label_names)
    std_df = pd.DataFrame(index=feature_df.index.values, data=y_hat_std, columns=[f"{cur_col}_std" for cur_col in model.label_names])
    result_df = pd.merge(est_df, std_df, right_index=True, left_index=True)

    print(f"Writing the result to {output_ffp}")
    result_df.to_csv(output_ffp, index_label="record_id")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "input_dir",
        type=str,
        help="Input data directory, can either contain a feature csv file for each "
        "component as generated by 'extract_features.py' or geonet V1A files",
    )
    parser.add_argument("output_ffp", type=str, help="Path for the output csv file")
    parser.add_argument("--model_dir", type=str, help="Path to the base model directory", default=Path(__file__).parent / ".." / "model")

    args = parser.parse_args()

    main(Path(args.input_dir), gm.utils.to_path(args.model_dir), Path(args.output_ffp))